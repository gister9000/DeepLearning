Usage: python NLP_RNN.py <Vanilla|GRU|LSTM> num_layers dropout bidirectional hidden_size seed
Example: python NLP_RNN.py Vanilla 2 0 0 150 456787

with hidden_size 150, all celly types behave the same (~75 acc)
hidden_size = [30, 150, 400]
num_layers = [2, 6, 30]
bi = [0, 1]
dropout = [0.05, 0.2, 0.5]

Fixed params:
    lr = 1e-4
    b_size = 32


SEEDS: [74732, 91273, 319, 99283, 4510]


### Experiment 1 - hidden size must be decent sized, although too much has no effect on accuracy, but slows down immensely
Trying low hidden size (30) but many layers (30)
python NLP_RNN.py Vanilla 30 0 0 30 319
python NLP_RNN.py GRU 30 0 0 30 319
python NLP_RNN.py LSTM 30 0 0 30 319

############################################################
Confusion matrix:  
[[895   0]
 [897   0]]
F1 score:	 nan
Average loss:	 0.6949953436851501
Accuracy:	 0.4994419642857143
############################################################
Evaluating model on test dataset after completion 
Confusion matrix:  
[[453   0]
 [411   0]]
F1 score:	 nan
Average loss:	 0.6920261979103088
Accuracy:	 0.5243055555555556
############################################################


### Experiment 2 - bidirectional provides slightly better results overall
                 - bigger size slighly better

python NLP_RNN.py Vanilla 4 0.05 0 300 99283
############################################################
F1 score:	 0.7490946714950852
Accuracy:	 0.7293526785714286
############################################################
F1 score:	 0.7891304347826087
Accuracy:	 0.7754629629629629
############################################################

python NLP_RNN.py Vanilla 4 0.05 1 300 99293
############################################################
F1 score:	 0.7547169811320754
Accuracy:	 0.7243303571428571
############################################################
F1 score:	 0.7656090071647901
Accuracy:	 0.7349537037037037
############################################################




python NLP_RNN.py GRU 4 0.05 0 300 99283 > GRU_4_005_300_99283.txt
############################################################
F1 score:	 0.799812030075188
Accuracy:	 0.7622767857142857
############################################################
F1 score:	 0.78196872125115
Accuracy:	 0.7256944444444444
############################################################


python NLP_RNN.py GRU 4 0.1 1 300 99293 > GRU_4_005_300_99283_bi.txt
############################################################
F1 score:	 0.8132315521628499
Accuracy:	 0.7952008928571429
############################################################
F1 score:	 0.7465753424657534
Accuracy:	 0.7430555555555556
############################################################





python NLP_RNN.py LSTM 4 0.2 1 300 99293 > LSTM_4_005_300_99283.txt
############################################################
F1 score:	 0.7436379492193913
Accuracy:	 0.7649742747292473
############################################################
F1 score:	 0.7542392349733292
Accuracy:	 0.7439823972932892
############################################################

python NLP_RNN.py LSTM 4 0.2 1 300 99293 > LSTM_4_005_300_99283_bi.txt
############################################################
F1 score:	 0.7633711793138891
Accuracy:	 0.7733187212778229
############################################################
F1 score:	 0.7524983289130111
Accuracy:	 0.7572837283187318
############################################################


