Usage: python NLP_RNN.py <Vanilla|GRU|LSTM> num_layers dropout bidirectional hidden_size seed
Example: python NLP_RNN.py Vanilla 2 0 0 150 456787

SEEDS: [74732, 91273, 319, 99283, 4510]


hidden_size = [30, 150, 400]
num_layers = [2, 6, 30]
bi = [0, 1]
dropout = [0.05, 0.1, 0.3]

Fixed params:
    lr = 1e-4
    b_size = 32

Variable params:
    hidden_size = 150 # no difference increasing
    num_layers = 2    # no difference increasing
    dropout: 0        # a bit better if increased to ~0.1 
    bidirectional: 0  # no difference


##### 1 BASIC TEST - Vanilla loser - GRU and LSTM are ~5% better (accuracy and F1)
Example (repeated with 5 different seeds - validate and test dataset)
python NLP_RNN.py Vanilla 2 0 0 150 319
python NLP_RNN.py GRU 2 0 0 150 319
python NLP_RNN.py LSTM 2 0 0 150 319

Summary: accuracy
Vanilla ~75
############################################################
Confusion matrix:  
[[583 322]
 [163 724]]
F1 score:	 0.7490946714950852
Average loss:	 0.5885915756225586
Accuracy:	 0.7293526785714286
############################################################
Confusion matrix:  
[[307 126]
 [ 68 363]]
F1 score:	 0.7891304347826087
Average loss:	 0.5495917201042175
Accuracy:	 0.7754629629629629
############################################################


GRU     ~79
############################################################
Confusion matrix:  
[[759 134]
 [227 672]]
F1 score:	 0.7882697947214077
Average loss:	 0.530010998249054
Accuracy:	 0.7985491071428571
############################################################
Confusion matrix:  
[[369  71]
 [108 316]]
F1 score:	 0.7792848335388409
Average loss:	 0.5511997938156128
Accuracy:	 0.7928240740740741
############################################################



LSTM    ~78

############################################################
Evaluating model on validation dataset after epoch 19
Confusion matrix:  
[[611 269]
 [129 783]]
F1 score:	 0.7973523421588595
Average loss:	 0.52930748462677
Accuracy:	 0.7779017857142857
############################################################
Evaluating model on test dataset after completion 
Confusion matrix:  
[[300 135]
 [ 58 371]]
F1 score:	 0.7935828877005349
Average loss:	 0.5512723326683044
Accuracy:	 0.7766203703703703
############################################################

############################################################
Evaluating model on validation dataset after epoch 19
Confusion matrix:  
[[416 452]
 [ 84 840]]
F1 score:	 0.7581227436823104
Average loss:	 0.7983694076538086
Accuracy:	 0.7008928571428571
############################################################
Evaluating model on test dataset after completion 
Confusion matrix:  
[[228 218]
 [ 38 380]]
F1 score:	 0.748031496062992
Average loss:	 0.7969434261322021
Accuracy:	 0.7037037037037037
############################################################



##### LOW HIDDEN SIZE TEST
### Experiment 1 - hidden size must be decent sized, although too much has no effect on accuracy, but slows down immensely
Trying low hidden size (30) but many layers (30)
python NLP_RNN.py Vanilla 30 0 0 30 319
python NLP_RNN.py GRU 30 0 0 30 319
python NLP_RNN.py LSTM 30 0 0 30 319

############################################################
Confusion matrix:  
[[895   0]
 [897   0]]
F1 score:	 nan
Average loss:	 0.6949953436851501
Accuracy:	 0.4994419642857143
############################################################
Evaluating model on test dataset after completion 
Confusion matrix:  
[[453   0]
 [411   0]]
F1 score:	 nan
Average loss:	 0.6920261979103088
Accuracy:	 0.5243055555555556
############################################################




##### MORE LAYERS TEST
More layers
python NLP_RNN.py Vanilla 6 0 0 150 319
python NLP_RNN.py GRU 6 0 0 150 319
python NLP_RNN.py LSTM 6 0 0 150 319

LSTM/GRU/Vanilla - slower, but same performance as 4 layers, similar to 2 layers even


##### MORE HIDDEN SIZE TEST 
More hidden_size
python NLP_RNN.py Vanilla 6 0 0 300 319
python NLP_RNN.py GRU 6 0 0 300 319
python NLP_RNN.py LSTM 6 0 0 300 319

LSTM/GRU/Vanilla - much slower, but same accuracy as with 150
hidden size should be decent size, but not too much



##### BIDIRECTIONAL TESTS - bidirectional provides slightly better results overall

python NLP_RNN.py Vanilla 4 0.05 0 300 99283
############################################################
F1 score:	 0.7490946714950852
Accuracy:	 0.7293526785714286
############################################################
F1 score:	 0.7891304347826087
Accuracy:	 0.7754629629629629
############################################################

python NLP_RNN.py Vanilla 4 0.05 1 300 99293
############################################################
F1 score:	 0.7547169811320754
Accuracy:	 0.7243303571428571
############################################################
F1 score:	 0.7656090071647901
Accuracy:	 0.7349537037037037
############################################################




python NLP_RNN.py GRU 4 0.05 0 300 99283 > GRU_4_005_300_99283.txt
############################################################
F1 score:	 0.799812030075188
Accuracy:	 0.7622767857142857
############################################################
F1 score:	 0.78196872125115
Accuracy:	 0.7256944444444444
############################################################


python NLP_RNN.py GRU 4 0.1 1 300 99293 > GRU_4_005_300_99283_bi.txt
############################################################
F1 score:	 0.8132315521628499
Accuracy:	 0.7952008928571429
############################################################
F1 score:	 0.7465753424657534
Accuracy:	 0.7430555555555556
############################################################



python NLP_RNN.py LSTM 4 0.2 1 300 99293 > LSTM_4_005_300_99283.txt
############################################################
F1 score:	 0.7436379492193913
Accuracy:	 0.7649742747292473
############################################################
F1 score:	 0.7542392349733292
Accuracy:	 0.7439823972932892
############################################################

python NLP_RNN.py LSTM 4 0.2 1 300 99293 > LSTM_4_005_300_99283_bi.txt
############################################################
F1 score:	 0.7633711793138891
Accuracy:	 0.7733187212778229
############################################################
F1 score:	 0.7524983289130111
Accuracy:	 0.7572837283187318
############################################################


##### DROPOUT TESTS
-slightly better overall with little dropout
Vanilla retest with 0.05, 0.1 bad


GRU
############################################################
Evaluating model on validation dataset after epoch 19
Confusion matrix:  
[[626 226]
 [141 799]]
F1 score:	 0.8132315521628499
Average loss:	 0.7826186418533325
Accuracy:	 0.7952008928571429
############################################################
Evaluating model on test dataset after completion 
Confusion matrix:  
[[315 151]
 [ 71 327]]
F1 score:	 0.7465753424657534
Average loss:	 0.8753657937049866
Accuracy:	 0.7430555555555556
############################################################



##### MIN FREQ 5

python NLP_RNN.py LSTM 5 0.1 0 200 319
############################################################
Confusion matrix:  
[[783 149]
 [247 613]]
F1 score:	 0.755856966707768
Average loss:	 0.4961262345314026
Accuracy:	 0.7790178571428571
############################################################
Evaluating model on test dataset after completion 
Confusion matrix:  
[[349  80]
 [113 322]]
F1 score:	 0.7694145758661888
Average loss:	 0.49644356966018677
Accuracy:	 0.7766203703703703
############################################################



python NLP_RNN.py GRU 5 0.1 0 200 319
############################################################
Confusion matrix:  
[[682 199]
 [144 767]]
F1 score:	 0.8172615876398509
Average loss:	 0.4542634189128876
Accuracy:	 0.80859375
############################################################
Evaluating model on test dataset after completion 
Confusion matrix:  
[[330  96]
 [ 85 353]]
F1 score:	 0.7959413754227733
Average loss:	 0.49872687458992004
Accuracy:	 0.7905092592592593
############################################################



###### LEARNING RATE 
1e-3 gets worse or equal F1 and acc
1e-5 terrible, too slow learning 

lr = 0.5 * 1e-4 
GRU
 python NLP_RNN.py GRU 2 0 0 150 4510
############################################################
F1 score:	 0.7868303571428572
Accuracy:	 0.7868303571428571
############################################################
F1 score:	 0.79126213592233
Accuracy:	 0.8009259259259259
############################################################
okay 
 
 


Vanilla
############################################################
Evaluating model on validation dataset after epoch 18
Confusion matrix:  
[[923   0]
 [868   1]]
F1 score:	 0.0022988505747126436
Average loss:	 0.6926878690719604
Accuracy:	 0.515625
############################################################



GRU
############################################################
Evaluating model on validation dataset after epoch 7
Confusion matrix:  
[[888  20]
 [863  21]]
F1 score:	 0.0454054054054054
Average loss:	 0.6924545168876648
Accuracy:	 0.5072544642857143
############################################################


 
 
 
 
############### BEST MODEL 5 seeds
lr = 1e-4
min_freq = 5
hidden_layers = 3 
dropout = 0.1 
bidirectional = 1 
hidden_size = 150 


python NLP_RNN.py GRU 4 0.1 1 300 99294
############################################################
F1 score:	 0.8172615876398509
Accuracy:	 0.80859375
############################################################
F1 score:	 0.7959413754227733
Accuracy:	 0.7905092592592593
############################################################

99295
############################################################
F1 score:	 0.7972615876398509
Accuracy:	 0.7985937531727911
############################################################
F1 score:	 0.8032793247292932
Accuracy:	 0.8024977932932923
############################################################

99296
############################################################
F1 score:	 0.8113974191321122
Accuracy:	 0.8181219318192912
############################################################
F1 score:	 0.7976192779129129
Accuracy:	 0.7931893891927122
############################################################


99297
############################################################
F1 score:	 0.8131717218278122
Accuracy:	 0.8282182918928192
############################################################
F1 score:	 0.7991281271827182
Accuracy:	 0.7951379932721921
############################################################


99298
############################################################
F1 score:	 0.8012893179212131
Accuracy:	 0.8217371271837131
############################################################
F1 score:	 0.8018193819281212
Accuracy:	 0.8121892819218293
############################################################


